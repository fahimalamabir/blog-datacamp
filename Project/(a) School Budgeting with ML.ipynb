{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the size of dataset, it is not included in this repository, however, you can download it through https://www.kaggle.com/jeromeblanchet/drivendatas-boxplots-for-education-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the challenge\n",
    "- Budgets for schools are huge, complex, and not standardize.\n",
    "- Hundreds of hours each year are spent manually labelling\n",
    "- Goal: Build a machine learning algorithm that can automate the process\n",
    "- Supervised Learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TrainingData.csv', <http.client.HTTPMessage at 0x1da00047088>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_2533/datasets/TrainingSetSample.csv'\n",
    "from urllib.request import urlretrieve\n",
    "urlretrieve(fn, 'TrainingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1560 entries, 0 to 1559\n",
      "Data columns (total 26 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              1560 non-null   int64  \n",
      " 1   Function                1560 non-null   object \n",
      " 2   Use                     1560 non-null   object \n",
      " 3   Sharing                 1560 non-null   object \n",
      " 4   Reporting               1560 non-null   object \n",
      " 5   Student_Type            1560 non-null   object \n",
      " 6   Position_Type           1560 non-null   object \n",
      " 7   Object_Type             1560 non-null   object \n",
      " 8   Pre_K                   1560 non-null   object \n",
      " 9   Operating_Status        1560 non-null   object \n",
      " 10  Object_Description      1461 non-null   object \n",
      " 11  Text_2                  382 non-null    object \n",
      " 12  SubFund_Description     1183 non-null   object \n",
      " 13  Job_Title_Description   1131 non-null   object \n",
      " 14  Text_3                  296 non-null    object \n",
      " 15  Text_4                  193 non-null    object \n",
      " 16  Sub_Object_Description  364 non-null    object \n",
      " 17  Location_Description    874 non-null    object \n",
      " 18  FTE                     449 non-null    float64\n",
      " 19  Function_Description    1340 non-null   object \n",
      " 20  Facility_or_Department  252 non-null    object \n",
      " 21  Position_Extra          1026 non-null   object \n",
      " 22  Total                   1542 non-null   float64\n",
      " 23  Program_Description     1192 non-null   object \n",
      " 24  Fund_Description        819 non-null    object \n",
      " 25  Text_1                  1132 non-null   object \n",
      "dtypes: float64(2), int64(1), object(23)\n",
      "memory usage: 317.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('TrainingData.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some of the column names correspond to features - descriptions of the budget items - such as the Job_Title_Description column. The values in this column tell us if a budget item is for a teacher, custodian, or other employee.\n",
    "\n",
    "and some columns correspond to the budget item labels you will be trying to predict with your model. For example, the Object_Type column describes whether the budget item is related classroom supplies, salary, travel expenses, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using df.info(), in the IPython Shell, we see figured out which columns of the data are numeric, specifically type float64. There are two numeric columns, called FTE and Total.\n",
    "\n",
    "FTE: Stands for \"full-time equivalent\". If the budget item is associated to an employee, this number tells us the percentage of full-time that the employee works. A value of 1 means the associated employee works for the school full-time. A value close to 0 means the item is associated to a part-time or contracted employee.\n",
    "Total: Stands for the total cost of the expenditure. This number tells us how much the budget item cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126071.000000</td>\n",
       "      <td>3.957220e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.426794</td>\n",
       "      <td>1.310586e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.573576</td>\n",
       "      <td>3.682254e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.087551</td>\n",
       "      <td>-8.746631e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000792</td>\n",
       "      <td>7.379770e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.130927</td>\n",
       "      <td>4.612300e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.652662e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.800000</td>\n",
       "      <td>1.297000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FTE         Total\n",
       "count  126071.000000  3.957220e+05\n",
       "mean        0.426794  1.310586e+04\n",
       "std         0.573576  3.682254e+05\n",
       "min        -0.087551 -8.746631e+07\n",
       "25%         0.000792  7.379770e+01\n",
       "50%         0.130927  4.612300e+02\n",
       "75%         1.000000  3.652662e+03\n",
       "max        46.800000  1.297000e+08"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'num employee')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['FTE'].dropna(), bins=10)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the datatypes\n",
    "- ML algorithms work on numbers, not strings\n",
    "- Need a numeric representation of these strings\n",
    "- Strings can be slow compared to numbers\n",
    "- In pandas, category dtype encodes categorical data numerically,\n",
    "Can speed up code\n",
    "\n",
    "### Exploring datatypes in pandas\n",
    "It's always good to know what datatypes you're working with, especially when the inefficient pandas type object may be involved. Towards that end, let's explore what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     23\n",
       "float64     2\n",
       "int64       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the labels as categorical variables\n",
    "Remember, your ultimate goal is to predict the probability that a certain label is attached to a budget line item. You just saw that many columns in your data are the inefficient object type. Does this include the labels you're trying to predict? Let's find out!\n",
    "\n",
    "There are 9 columns of labels in the dataset. Each of these columns is a category that has many possible values it can take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type',\n",
    "          'Object_Type', 'Pre_K', 'Operating_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Use                 category\n",
      "Sharing             category\n",
      "Reporting           category\n",
      "Student_Type        category\n",
      "Position_Type       category\n",
      "Object_Type         category\n",
      "Pre_K               category\n",
      "Operating_Status    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert df[LABELS] to a category type\n",
    "df[LABELS] = categorize_label(df[LABELS])\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_labels = df[LABELS].apply(pd.Series.nunique, axis=0)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "num_unique_labels.plot(kind='bar')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we measure success?\n",
    "- Accuracy can be misleading when classes are imbalanced\n",
    "    - Legitmate email: 99%, Spam: 1%\n",
    "    - Model that never predicts spam will be 99% accurate!\n",
    "- Metric used in this problem: log loss\n",
    "    - Loss function\n",
    "    - Measure of error\n",
    "    - Want to minimize the error (unlike accuracy)\n",
    "- Log loss binary classification\n",
    "     = $$-\\frac{1}{N}\\sum_{i=1}^N (y_i \\log (p_i))+ (1-y_i)\\log (1-p_i)) $$\n",
    "    - Actual value: $y: {1=\\text{yes}, ~~0=\\text{no}}~~~y:1=yes,0=no$\n",
    "    - Prediction (probability that the value is 1): pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing log loss with NumPy\n",
    "To see how the log loss metric handles the trade-off between accuracy and confidence, we will use some sample data generated with NumPy and compute the log loss using the provided function compute_log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_loss(predicted, actual, eps=1e-14):\n",
    "    \"\"\"Compute the logarithmic loss between predicted and\n",
    "       actual when these are 1D arrays\n",
    "\n",
    "       :param predicted: The predicted probabilties as floats between 0-1\n",
    "       :param actual: The actual binary labels. Either 0 or 1\n",
    "       :param eps (optional): log(0) is inf, so we need to offset our\n",
    "                               predicted values slightly by eps from 0 or 1.\n",
    "    \"\"\"\n",
    "    predicted = np.clip(predicted, eps, 1-eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted) + (1 - actual) * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_loss(predicted, actual, eps=1e-14):\n",
    "    \"\"\"Compute the logarithmic loss between predicted and\n",
    "       actual when these are 1D arrays\n",
    "\n",
    "       :param predicted: The predicted probabilties as floats between 0-1\n",
    "       :param actual: The actual binary labels. Either 0 or 1\n",
    "       :param eps (optional): log(0) is inf, so we need to offset our\n",
    "                               predicted values slightly by eps from 0 or 1.\n",
    "    \"\"\"\n",
    "    predicted = np.clip(predicted, eps, 1-eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted) + (1 - actual) * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_confident = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.05])\n",
    "correct_not_confident = np.array([0.65, 0.65, 0.65, 0.65, 0.65, 0.35, 0.35, 0.35, 0.35, 0.35])\n",
    "wrong_not_confident = np.array([0.35, 0.35, 0.35, 0.35, 0.35, 0.65, 0.65, 0.65, 0.65, 0.65])\n",
    "wrong_confident = np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.95, 0.95, 0.95, 0.95, 0.95])\n",
    "actual_labels = np.array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss, correct and confident: 0.05129329438755058\n",
      "Log loss, correct and not confident: 0.4307829160924542\n",
      "Log loss, wrong and not confident: 1.049822124498678\n",
      "Log loss, wrong and confident: 2.9957322735539904\n",
      "Log loss, actual labels: 9.99200722162646e-15\n"
     ]
    }
   ],
   "source": [
    "correct_confident_loss = compute_log_loss(correct_confident, actual_labels)\n",
    "print(\"Log loss, correct and confident: {}\".format(correct_confident_loss)) \n",
    "\n",
    "# Compute log loss for 2nd case\n",
    "correct_not_confident_loss = compute_log_loss(correct_not_confident, actual_labels)\n",
    "print(\"Log loss, correct and not confident: {}\".format(correct_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 3rd case\n",
    "wrong_not_confident_loss = compute_log_loss(wrong_not_confident, actual_labels)\n",
    "print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 4th case\n",
    "wrong_confident_loss = compute_log_loss(wrong_confident, actual_labels)\n",
    "print(\"Log loss, wrong and confident: {}\".format(wrong_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for actual labels\n",
    "actual_labels_loss = compute_log_loss(actual_labels, actual_labels)\n",
    "print(\"Log loss, actual labels: {}\".format(actual_labels_loss)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to build model\n",
    "## Setting up a train-test split in scikit-learn\n",
    "\n",
    "The first step is to split the data into a training set and a test set. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. We provide a function that will make sure at least min_count examples of each label appear in each split: multilabel_train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).any():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a simple model that uses just the numeric columns of your DataFrame when calling multilabel_train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   FTE     320222 non-null  float64\n",
      " 1   Total   320222 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 72072\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   FTE     80055 non-null  float64\n",
      " 1   Total   80055 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 34.2 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 72072\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000).copy()\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only, label_dummies,\n",
    "                                                               size=0.2, seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")\n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")\n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")\n",
    "print(y_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "We will import the logistic regression and one versus rest classifiers in order to fit a multi-class logistic regression model to the NUMERIC_COLUMNS of your feature data.\n",
    "\n",
    "Then we'll test and print the accuracy with the .score() method to see the results of training.\n",
    "\n",
    "Before we train!we're ultimately going to be using logloss to score our model, so don't worry too much about the accuracy here. Keep in mind that we're throwing away all of the text data in the dataset - that's by far most of the data!  We're just interested in getting things up and running at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! The good news is that our workflow didn't cause any errors. The bad news is that the model scored the lowest possible accuracy: 0.0! The reason is, we just threw away ALL of the text data in the budget. Later, we won't. Before we add the text data, let's see how the model does when scored by log loss.\n",
    "\n",
    "### Making predictions\n",
    "We need to remind ourselves that the original goal is to predict the probability of each label. Now, we'll do just that by using the .predict_proba() method on our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('HoldoutData.csv', <http.client.HTTPMessage at 0x1da002c6ec8>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_2826/datasets/TestSetSample.csv'\n",
    "from urllib.request import urlretrieve\n",
    "urlretrieve(fn, 'HoldoutData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = pd.read_csv('HoldoutData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load path to pred\n",
    "PATH_TO_PREDICTIONS = \"predictions.csv\"\n",
    "# Load path to holdout\n",
    "PATH_TO_HOLDOUT_DATA = \"https://s3.amazonaws.com/assets.datacamp.com/production/course_2826/datasets/TestSetSample.csv\"\n",
    "PATH_TO_HOLDOUT_LABELS = \"https://s3.amazonaws.com/assets.datacamp.com/production/course_2826/datasets/TestSetLabelsSample.csv\"\n",
    "\n",
    "# SCORING UTILITIES\n",
    "\n",
    "BOX_PLOTS_COLUMN_INDICES = [range(37),\n",
    " range(37,48),\n",
    " range(48,51),\n",
    " range(51,76),\n",
    " range(76,79),\n",
    " range(79,82),\n",
    " range(82,87),\n",
    " range(87,96),\n",
    " range(96,104)]\n",
    "\n",
    "def _multi_multi_log_loss(predicted,\n",
    "    actual,\n",
    "    class_column_indices=BOX_PLOTS_COLUMN_INDICES,\n",
    "    eps=1e-15):\n",
    "\n",
    "    class_scores = np.ones(len(class_column_indices), dtype=np.float64)\n",
    "\n",
    "    # calculate log loss for each set of columns that belong to a class:\n",
    "    for k, this_class_indices in enumerate(class_column_indices):\n",
    "        # get just the columns for this class\n",
    "        preds_k = predicted[:, this_class_indices].astype(np.float64)\n",
    "\n",
    "        # normalize so probabilities sum to one (unless sum is zero, then we clip)\n",
    "        preds_k /= np.clip(preds_k.sum(axis=1).reshape(-1, 1), eps, np.inf)\n",
    "\n",
    "        actual_k = actual[:, this_class_indices]\n",
    "\n",
    "        # shrink predictions so\n",
    "        y_hats = np.clip(preds_k, eps, 1 - eps)\n",
    "        sum_logs = np.sum(actual_k * np.log(y_hats))\n",
    "        class_scores[k] = (-1.0 / actual.shape[0]) * sum_logs\n",
    "\n",
    "        return np.average(class_scores)\n",
    "\n",
    "\n",
    "def score_submission(pred_path=PATH_TO_PREDICTIONS, holdout_path=PATH_TO_HOLDOUT_LABELS):\n",
    "    # this happens on the backend to get the score\n",
    "    holdout_labels = pd.get_dummies(\n",
    "    pd.read_csv(holdout_path, index_col=0)\n",
    "    .apply(lambda x: x.astype('category'), axis=0)\n",
    "    )\n",
    "\n",
    "    preds = pd.read_csv(pred_path, index_col=0)\n",
    "\n",
    "    # make sure that format is correct\n",
    "    assert (preds.columns == holdout_labels.columns).all()\n",
    "    assert (preds.index == holdout_labels.index).all()\n",
    "\n",
    "    return _multi_multi_log_loss(preds.values, holdout_labels.values)\n",
    "\n",
    "# Load holdout data\n",
    "holdout = pd.read_csv(PATH_TO_HOLDOUT_DATA, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model, trained with numeric data only, yields logloss score: 1.2435086008540268\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS]).columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('predictions.csv')\n",
    "\n",
    "# Submit the predictions for scoring: score\n",
    "score = score_submission(pred_path='predictions.csv')\n",
    "\n",
    "# Print score\n",
    "print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very brief introduction to NLP\n",
    "### Creating a bag-of-words in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 123 tokens in Position_Extra if we split on non-alpha numeric\n",
      "['1st', '2nd', '3rd', 'a', 'ab', 'additional', 'adm', 'administrative', 'and', 'any', 'art', 'assessment', 'assistant', 'asst', 'athletic']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining text columns for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna('', inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(str(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 tokens in the dataset\n",
      "There are 36 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVecotrizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
